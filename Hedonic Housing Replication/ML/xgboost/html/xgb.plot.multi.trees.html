<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Project all trees on one tree and plot it</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for xgb.plot.multi.trees {xgboost}"><tr><td>xgb.plot.multi.trees {xgboost}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Project all trees on one tree and plot it</h2>

<h3>Description</h3>

<p>Visualization of the ensemble of trees as a single collective unit.
</p>


<h3>Usage</h3>

<pre>
xgb.plot.multi.trees(model, feature_names = NULL, features_keep = 5,
  plot_width = NULL, plot_height = NULL, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>model</code></td>
<td>
<p>dump generated by the <code>xgb.train</code> function.</p>
</td></tr>
<tr valign="top"><td><code>feature_names</code></td>
<td>
<p>names of each feature as a <code>character</code> vector. Can be extracted from a sparse matrix (see example). If model dump already contains feature names, this argument should be <code>NULL</code>.</p>
</td></tr>
<tr valign="top"><td><code>features_keep</code></td>
<td>
<p>number of features to keep in each position of the multi trees.</p>
</td></tr>
<tr valign="top"><td><code>plot_width</code></td>
<td>
<p>width in pixels of the graph to produce</p>
</td></tr>
<tr valign="top"><td><code>plot_height</code></td>
<td>
<p>height in pixels of the graph to produce</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>currently not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function tries to capture the complexity of gradient boosted tree ensemble 
in a cohesive way. 
</p>
<p>The goal is to improve the interpretability of the model generally seen as black box.
The function is dedicated to boosting applied to decision trees only.
</p>
<p>The purpose is to move from an ensemble of trees to a single tree only.
</p>
<p>It takes advantage of the fact that the shape of a binary tree is only defined by 
its deepness (therefore in a boosting model, all trees have the same shape). 
</p>
<p>Moreover, the trees tend to reuse the same features.
</p>
<p>The function will project each tree on one, and keep for each position the 
<code>features_keep</code> first features (based on Gain per feature measure).
</p>
<p>This function is inspired by this blog post:
<a href="https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/">https://wellecks.wordpress.com/2015/02/21/peering-into-the-black-box-visualizing-lambdamart/</a>
</p>


<h3>Value</h3>

<p>Two graphs showing the distribution of the model deepness.
</p>


<h3>Examples</h3>

<pre>
data(agaricus.train, package='xgboost')

bst &lt;- xgboost(data = agaricus.train$data, label = agaricus.train$label, max_depth = 15,
                 eta = 1, nthread = 2, nrounds = 30, objective = "binary:logistic",
                 min_child_weight = 50)

p &lt;- xgb.plot.multi.trees(model = bst, feature_names = colnames(agaricus.train$data),
                          features_keep = 3)
print(p)

</pre>

<hr /><div style="text-align: center;">[Package <em>xgboost</em> version 0.6.4.1 <a href="00Index.html">Index</a>]</div>
</body></html>
